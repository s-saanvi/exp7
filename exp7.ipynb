import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error

# --- Linear Regression: California Housing ---
X1, y1 = fetch_california_housing(return_X_y=True)
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)
scaler = StandardScaler()
X1_train = scaler.fit_transform(X1_train)
X1_test = scaler.transform(X1_test)

lr_model = LinearRegression().fit(X1_train, y1_train)
y1_pred = lr_model.predict(X1_test)

print(f"California Housing Linear Regression MSE: {mean_squared_error(y1_test, y1_pred):.4f}")
plt.scatter(y1_test, y1_pred, alpha=0.5)
plt.plot([y1_test.min(), y1_test.max()], [y1_test.min(), y1_test.max()], 'r--')
plt.xlabel("Actual"), plt.ylabel("Predicted")
plt.title("Linear Regression: California Housing")
plt.show()

# --- Polynomial Regression: MPG dataset ---
df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv").dropna()
X2, y2 = df[['horsepower']].astype(float), df['mpg']
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)
degree = 3

poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())
poly_model.fit(X2_train, y2_train)
y2_pred = poly_model.predict(X2_test)

print(f"MPG Polynomial Regression (degree {degree}) MSE: {mean_squared_error(y2_test, y2_pred):.4f}")
sorted_idx = np.argsort(X2_test.values.flatten())
plt.scatter(X2_test, y2_test, alpha=0.5, label="Actual")
plt.plot(X2_test.values.flatten()[sorted_idx], y2_pred[sorted_idx], 'r', label="Polynomial Fit")
plt.xlabel("Horsepower"), plt.ylabel("MPG")
plt.title(f"Polynomial Regression (degree {degree})")
plt.legend(), plt.show()
